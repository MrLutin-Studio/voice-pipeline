# ğŸ¤ Full Voice Pipeline - STT â†’ LLM â†’ TTS

## Vue d'ensemble

**full_voice_pipeline.py** implÃ©mente une pipeline complÃ¨te:

```
Audio Input 
    â†“
ğŸ¤ Whisper STT (CPU)  â†’ Transcrit en texte franÃ§ais
    â†“
ğŸ§  Claude LLM         â†’ GÃ©nÃ¨re rÃ©ponse intelligente
    â†“
ğŸ¤ XTTS v2 TTS (GPU)  â†’ SynthÃ©tise en audio clonÃ©e
    â†“
Audio Output
```

## Configuration

### Dispositifs
- **Whisper:** CPU (Ã©conomise VRAM)
- **Claude:** API (online) ou offline mock
- **XTTS:** GPU (CUDA)

### Avantages
- âœ… Optimisation VRAM (2x2GB GPUs)
- âœ… Conversion audio â†’ texte â†’ rÃ©ponse â†’ audio
- âœ… Support franÃ§ais complet
- âœ… Mode offline (sans API Claude)
- âœ… Historique conversation

## Installation

```bash
cd /mnt/storage/projects/voice-pipeline
source voice_env/bin/activate

# VÃ©rifier les dÃ©pendances
python3 -c "import whisper; print('âœ“ Whisper')"
python3 -c "import torch; print('âœ“ PyTorch')"
python3 -c "from TTS.api import TTS; print('âœ“ XTTS')"
```

## Utilisation

### Mode demo (avec sample.wav)
```bash
python3 full_voice_pipeline.py
# Output: output/response_2.wav
```

### Mode custom (avec votre audio)
```bash
python3 full_voice_pipeline.py /path/to/your_audio.wav
# Output: output/response_2.wav
```

## RÃ©sultats

```
ğŸ¤ Initializing Voice Pipeline...
ğŸ”§ Whisper: CPU
ğŸ”§ XTTS: CUDA
ğŸ“¥ Loading Whisper...
  âœ“ Whisper ready
ğŸ“¥ Loading Claude...
  âœ“ Claude ready
ğŸ“¥ Loading XTTS v2...
  âœ“ XTTS ready

âœ… **Voice Pipeline initialized!**

ğŸ“ Demo mode - Processing sample audio...
ğŸ¤ Transcribing: samples/sample.wav
  Recognized: Des marages des diagnostic...
ğŸ§  Processing: Des marages des diagnostic...
  Response: J'ai une petite erreur de connexion...
ğŸ¤ Generating speech: J'ai une petite erreur...
  âœ“ Saved: output/response_2.wav

âœ… Morwintar says: J'ai une petite erreur de connexion!
```

## Performance

| Stage | Device | Time | Status |
|-------|--------|------|--------|
| **Whisper STT** | CPU | ~5-10s | âœ… |
| **Claude LLM** | API | ~1-2s | âœ… |
| **XTTS TTS** | GPU | ~2-3s | âœ… |
| **Total** | Mixed | ~10-15s | âœ… |

## API Keys

### Claude (Optionnel)
```bash
export ANTHROPIC_API_KEY="sk-ant-..."
python3 full_voice_pipeline.py
```

Sans API key â†’ Mode offline (rÃ©ponses mock)

## Architecture

```python
# Pipeline object
anthropic = Anthropic()  # Claude
whisper_model = whisper.load_model("base", device="cpu")
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=True)

# Functions
def stt(audio_path) â†’ str          # Whisper transcription
def llm(user_text) â†’ str           # Claude response
def tts_generate(text) â†’ wav       # XTTS synthesis
def process_voice_input(audio) â†’ (response, history)  # Full pipeline
```

## Limitations

- **GPU Memory:** 2GB max (OK pour XTTS seul)
- **Audio Format:** WAV 16-bit mono/stÃ©rÃ©o recommandÃ©
- **Langue:** FranÃ§ais principalement (configurable)
- **Claude:** Besoin d'API key pour rÃ©ponses intelligentes

## Optimisations Futures

1. Voice Activity Detection (VAD) - dÃ©tecter silence
2. Streaming audio processing
3. Multi-language support
4. GPU memory pooling
5. Caching des rÃ©ponses frecuentes

---

_Morwintar - Listen, Think, Speak_ ğŸ¤ğŸ§ ğŸ¤

Date: 2026-02-21
