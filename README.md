# ğŸ¤ Voice Pipeline

> **Parle â†’ Comprend â†’ RÃ©pond avec ta voix**

Un assistant vocal IA qui clone ta voix pour te rÃ©pondre naturellement.

---

## ğŸ¤” C'est quoi?

Voice Pipeline est un systÃ¨me conversationnel qui:

1. **Ã‰coute** ta voix (ou lit ton texte)
2. **Comprend** ce que tu dis grÃ¢ce Ã  l'IA
3. **RÃ©pond** avec une voix clonÃ©e (la tienne ou une autre)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ¤ Toi    â”‚ â†’  â”‚  ğŸ§  Claude  â”‚ â†’  â”‚  ğŸ”Š RÃ©ponse â”‚
â”‚  (Audio)    â”‚    â”‚   (IA)      â”‚    â”‚ (Ta voix!)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                  â†“                  â†“
   Whisper          GÃ©nÃ¨re une         XTTS v2
  (transcrit)        rÃ©ponse        (clone vocal)
```

---

## âš¡ DÃ©marrage rapide

### 1. Installation

```bash
# Clone le repo
git clone https://github.com/MrLutin-Studio/voice-pipeline.git
cd voice-pipeline

# CrÃ©e un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Installe les dÃ©pendances
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Ajoute ta clÃ© API Anthropic
export ANTHROPIC_API_KEY="sk-ant-..."
```

### 3. Utilisation

```bash
# Depuis un fichier audio
python voice_pipeline.py --input ma_question.wav

# Depuis du texte
python voice_pipeline.py --text "Salut, Ã§a va?"

# Enregistrer depuis le micro
python voice_pipeline.py --record
```

---

## ğŸ™ï¸ Le Sample Vocal

Pour que l'IA parle avec **ta voix**, il faut un sample:

| CritÃ¨re | Recommandation |
|---------|----------------|
| **Format** | WAV (16kHz ou 22kHz) |
| **DurÃ©e** | 6 Ã  30 secondes |
| **QualitÃ©** | Propre, sans bruit de fond |
| **Contenu** | Parle naturellement, phrases variÃ©es |

Place ton sample dans `samples/sample.wav` ou spÃ©cifie-le avec `--voice`.

---

## âš™ï¸ Configuration avancÃ©e

Tout se configure dans `config.json`:

```json
{
  "whisper": {
    "model": "base",       // tiny, base, small, medium, large
    "language": "fr"
  },
  "claude": {
    "model": "claude-haiku-4-5",
    "system_prompt": "Tu es un assistant sympa..."
  },
  "tts": {
    "language": "fr",
    "voice_sample": "samples/sample.wav"
  }
}
```

---

## ğŸ“‹ Options CLI

| Option | Description |
|--------|-------------|
| `--input`, `-i` | Fichier audio d'entrÃ©e |
| `--text`, `-t` | Texte d'entrÃ©e (skip transcription) |
| `--voice`, `-v` | Sample vocal (dÃ©faut: config.json) |
| `--output`, `-o` | Fichier audio de sortie |
| `--record`, `-r` | Enregistrer depuis le micro |
| `--duration`, `-d` | DurÃ©e d'enregistrement (dÃ©faut: 5s) |
| `--device` | Forcer `cuda` ou `cpu` |

---

## ğŸ’» PrÃ©requis systÃ¨me

- **Python** 3.10+
- **GPU** recommandÃ© (NVIDIA + CUDA) â€” ~6GB VRAM
- **CPU** possible mais plus lent
- **ClÃ© API** [Anthropic](https://console.anthropic.com/)

---

## ğŸ› ProblÃ¨mes courants

**"CUDA out of memory"**
â†’ Utilise `--device cpu` ou un modÃ¨le Whisper plus petit (`tiny`)

**Voix robotique ou dÃ©formÃ©e**
â†’ AmÃ©liore ton sample vocal (plus long, plus propre)

**"No module named 'TTS'"**
â†’ `pip install coqui-tts`

---

## ğŸ“ Structure du projet

```
voice-pipeline/
â”œâ”€â”€ voice_pipeline.py   # Script principal
â”œâ”€â”€ config.json         # Configuration
â”œâ”€â”€ requirements.txt    # DÃ©pendances Python
â”œâ”€â”€ samples/            # Samples vocaux
â”‚   â””â”€â”€ sample.wav
â””â”€â”€ output/             # Fichiers gÃ©nÃ©rÃ©s
```

---

## ğŸ“œ Licence

Projet expÃ©rimental â€” usage personnel.  
XTTS v2 sous [Coqui Public Model License](https://coqui.ai/cpml).

---

<p align="center">
  CrÃ©Ã© par <b>Morwintar</b> ğŸ–¤ avec l'aide de <b>Delta_x1988</b> et <b>GhostNode</b>
</p>
